{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = \"SharkTank\"\n",
    "spark = SparkSession.builder.appName(app_name).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_data_file = \"/FileStore/tables/S1_8Sharktankpitchesdeals.csv\"\n",
    "pitch_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pitches = spark.read \\\n",
    "  .format(\"com.databricks.spark.csv\")\\\n",
    "  .options(header='true', inferSchema=\"true\")\\\n",
    "  .load(pitch_data_file)\n",
    "df_pitches.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "secret_name = \"ut/finalproject/sharktank\"\n",
    "region_name = \"us-east-2\"\n",
    "access_key = \"ACCESS KEY\"\n",
    "secret_key = \"SECRET ACCESS KEY\"\n",
    "\n",
    "session = boto3.session.Session(aws_access_key_id=access_key, aws_secret_access_key=secret_key, region_name=region_name)\n",
    "client = session.client('secretsmanager')\n",
    "secret_value = client.get_secret_value(SecretId=secret_name)\n",
    "# secret_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_connection(secret_value):\n",
    "  return json.loads(secret_value['SecretString'])\n",
    "# get_connection(secret_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = get_connection(secret_value)\n",
    "\n",
    "# Postgres credentials\n",
    "jdbcHostname = connection['host']\n",
    "jdbcPort = connection['port']\n",
    "jdbcDatabase = \"postgres\"\n",
    "dialect = \"postgresql\"\n",
    "jdbcUsername = connection['username']\n",
    "jdbcPassword = connection['password']\n",
    "\n",
    "jdbcUrl = f\"jdbc:{dialect}://{jdbcHostname}:{jdbcPort}/{jdbcDatabase}\"\n",
    "connectionProperties = {\n",
    "  \"user\" : jdbcUsername,\n",
    "  \"password\" : jdbcPassword,\n",
    "  \"driver\" : \"org.postgresql.Driver\"\n",
    "}\n",
    "# for mysql driver = com.mysql.jdbc.Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbcUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectionProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"user_data\"\n",
    "mode = \"overwrite\"\n",
    "df_pitches.write.jdbc(jdbcUrl, table, mode, connectionProperties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.jdbc(url=jdbcUrl, table=table, properties=connectionProperties)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
